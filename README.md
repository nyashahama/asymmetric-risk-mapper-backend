# Asymmetric Risk Mapper â€” Backend

A Go backend that powers a paid, one-shot business risk assessment tool. Users answer a questionnaire, pay via Stripe, and receive a personalised risk report generated by an AI model â€” delivered by email and accessible via a permanent tokenised link.

---

## Table of Contents

- [How It Works](#how-it-works)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Prerequisites](#prerequisites)
- [Getting Started](#getting-started)
- [Configuration](#configuration)
- [Database](#database)
- [API Reference](#api-reference)
- [Architecture Notes](#architecture-notes)
- [Running Tests](#running-tests)
- [Docker](#docker)
- [Deployment](#deployment)

---

## How It Works

```
Browser                     Backend                        External
  â”‚                            â”‚                              â”‚
  â”œâ”€ POST /session â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º creates anon session         â”‚
  â”œâ”€ PUT  /session/:id/answers â–º upserts answers              â”‚
  â”œâ”€ POST /session/:id/checkoutâ–º creates Stripe PaymentIntent â”‚
  â”‚                            â”‚                              â”‚
  â”‚      [user pays in browser via Stripe.js]                 â”‚
  â”‚                            â”‚                              â”‚
  â”‚                 POST /webhooks/stripe â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Stripeâ”‚
  â”‚                            â”‚  payment_intent.succeeded    â”‚
  â”‚                            â”œâ”€ creates report row          â”‚
  â”‚                            â”œâ”€ sends receipt email â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Resend
  â”‚                            â””â”€ enqueues scoring job        â”‚
  â”‚                                        â”‚                  â”‚
  â”‚                            [worker picks up job]          â”‚
  â”‚                            â”œâ”€ scores all answers          â”‚
  â”‚                            â”œâ”€ calls AI for hedge text â”€â”€â”€â–ºâ”‚ DeepSeek / Anthropic
  â”‚                            â”œâ”€ persists risk_results       â”‚
  â”‚                            â””â”€ sends report-ready email â”€â”€â–ºâ”‚ Resend
  â”‚                            â”‚                              â”‚
  â”œâ”€ GET /report/:token â”€â”€â”€â”€â”€â”€â”€â–º serves completed report      â”‚
```

---

## Tech Stack

| Concern | Choice |
|---|---|
| Language | Go 1.23 |
| HTTP router | [chi](https://github.com/go-chi/chi) |
| Database | PostgreSQL 16 |
| Query generation | [sqlc](https://sqlc.dev) |
| Migrations | [golang-migrate](https://github.com/golang-migrate/migrate) |
| Payments | Stripe (PaymentIntents API) |
| AI | DeepSeek (primary) Â· Anthropic Claude (fallback) |
| Email | Resend |
| Containerisation | Docker (multi-stage, scratch final image) |

---

## Project Structure

```
.
â”œâ”€â”€ cmd/                      # Command-line applications
â”‚   â”œâ”€â”€ api/                  # Main API server
â”‚   â””â”€â”€ migrate/              # Database migration runner
â”œâ”€â”€ internal/                 # Internal Go packages
â”‚   â”œâ”€â”€ db/                   # sqlc-generated database code
â”‚   â”œâ”€â”€ api/                  # API handlers and business logic
â”‚   â”œâ”€â”€ middleware/           # HTTP middleware
â”‚   â”œâ”€â”€ config/               # Configuration management
â”‚   â””â”€â”€ models/               # Data models
â”œâ”€â”€ migrations/               # Database migration files
â”œâ”€â”€ sql/                      # SQL queries for sqlc
â”‚   â””â”€â”€ queries.sql           # Query definitions
â”œâ”€â”€ docker-compose.yml        # Local development stack
â”œâ”€â”€ Dockerfile                # Production-ready image
â”œâ”€â”€ go.mod & go.sum          # Go dependencies
â””â”€â”€ sqlc.yaml                # sqlc configuration
```

---

## Prerequisites

- **Go 1.23+** â€” [install](https://go.dev/dl/)
- **Docker + Docker Compose** â€” for the local Postgres instance
- **sqlc** â€” `go install github.com/sqlc-dev/sqlc/cmd/sqlc@latest`
- **golang-migrate** â€” `go install -tags 'postgres' github.com/golang-migrate/migrate/v4/cmd/migrate@latest`

---

## Getting Started

```bash
# 1. Clone the repo
git clone https://github.com/nyashahama/asymmetric-risk-mapper-backend.git
cd asymmetric-risk-mapper-backend

# 2. Copy and fill in secrets
cp .env.example .env
# edit .env â€” at minimum: DATABASE_URL, STRIPE_*, RESEND_API_KEY, and one AI key

# 3. Start Postgres
docker compose up -d db

# 4. Run migrations
migrate -path migrations -database "$DATABASE_URL" up

# 5. Run the server (reads .env automatically)
go run ./cmd/api
```

The server starts on `:8080`. Hit `http://localhost:8080/healthz` to confirm it's up.

---

## Configuration

All configuration is read from environment variables. In development, a `.env` file in the working directory is loaded automatically â€” no wrapper command needed.

In production (Docker, Railway, Fly.io), set variables directly in the platform's environment â€” the `.env` file is ignored if the variables are already set in the shell.

| Variable | Required | Default | Description |
|---|---|---|---|
| `DATABASE_URL` | âœ… | â€” | Postgres DSN, e.g. `postgres://user:pass@host:5432/db?sslmode=require` |
| `STRIPE_SECRET_KEY` | âœ… | â€” | Stripe secret key (`sk_live_...` or `sk_test_...`) |
| `STRIPE_WEBHOOK_SECRET` | âœ… | â€” | Stripe webhook signing secret (`whsec_...`) |
| `RESEND_API_KEY` | âœ… | â€” | Resend API key |
| `ANTHROPIC_API_KEY` | âš  one of | â€” | Anthropic API key |
| `DEEPSEEK_API_KEY` | âš  one of | â€” | DeepSeek API key (used as primary if set) |
| `PORT` | | `8080` | HTTP listen port |
| `ENV` | | `development` | `development` \| `staging` \| `production` |
| `BASE_URL` | | `http://localhost:8080` | Used to build report access links in emails |
| `ANTHROPIC_MODEL` | | `claude-opus-4-6` | Model name passed to the Anthropic API |
| `DEEPSEEK_MODEL` | | `deepseek-chat` | Model name passed to the DeepSeek API |
| `EMAIL_FROM_ADDR` | | `reports@asymmetricrisk.com` | Sender address |
| `EMAIL_FROM_NAME` | | `Asymmetric Risk` | Sender display name |
| `WORKER_COUNT` | | `3` | Number of concurrent job goroutines |
| `POLL_INTERVAL` | | `30s` | How often the worker polls for pending jobs |
| `JOB_TIMEOUT` | | `5m` | Max time allowed for a single scoring job |
| `MAX_RETRIES` | | `3` | Max job retry attempts before marking error |

**AI provider precedence:** if both `ANTHROPIC_API_KEY` and `DEEPSEEK_API_KEY` are set, DeepSeek is used as the primary and Anthropic as the automatic fallback. If only one is set, that provider is used exclusively.

---

## Database

### Schema management

The schema lives in `sql/schema.sql` (source of truth for sqlc) and is applied in production via migration files in `migrations/`.

```bash
# Apply all pending migrations
migrate -path migrations -database "$DATABASE_URL" up

# Roll back the last migration
migrate -path migrations -database "$DATABASE_URL" down 1

# Check current version
migrate -path migrations -database "$DATABASE_URL" version
```

### Regenerating sqlc code

After editing `sql/queries.sql` or `sql/schema.sql`:

```bash
sqlc generate
```

The generated code lands in `internal/db/` â€” commit it alongside the SQL changes. Never edit `internal/db/` directly.

---

## API Reference

All session-scoped routes require the `X-Anon-Token` header â€” the token returned when the session was created.

### `POST /api/session`
Creates an anonymous session. Call this once when the assessment page loads.

**Request body** (all fields optional):
```json
{ "biz_name": "Acme Co", "industry": "SaaS", "stage": "growth" }
```

**Response `201`:**
```json
{ "session_id": "uuid", "anon_token": "hex64" }
```

---

### `PATCH /api/session/:sessionID/context`
Updates the business context (Step 1 of the assessment). Requires `X-Anon-Token`.

**Request body:**
```json
{ "biz_name": "Acme Co", "industry": "SaaS", "stage": "growth" }
```

---

### `PUT /api/session/:sessionID/answers`
Batch-upserts answers. Safe to replay â€” fully idempotent. Requires `X-Anon-Token`.

**Request body:**
```json
{
  "answers": [
    { "question_id": "q_cash_runway", "answer_text": "Less than 3 months" },
    { "question_id": "q_key_person", "answer_text": "Yes", "client_p": 8, "client_i": 9 }
  ]
}
```

---

### `POST /api/session/:sessionID/checkout`
Creates a Stripe PaymentIntent and returns its `client_secret`. The browser passes this to Stripe.js to render the payment UI. Requires `X-Anon-Token`.

**Request body:**
```json
{ "email": "user@example.com" }
```

**Response `200`:**
```json
{ "client_secret": "pi_xxx_secret_xxx", "is_existing": false }
```

---

### `POST /api/webhooks/stripe`
Receives Stripe webhook events. Stripe signature verification is enforced. No auth header needed â€” Stripe signs the payload with `STRIPE_WEBHOOK_SECRET`.

Handled events: `payment_intent.succeeded`, `payment_intent.payment_failed`, `charge.refunded`.

---

### `GET /api/report/:accessToken`
Returns the completed report. No authentication â€” the access token is the only credential. Returns `202 Accepted` while the report is still being generated so clients can poll.

**Response `200` (ready):**
```json
{
  "report_id": "uuid",
  "status": "ready",
  "biz_name": "Acme Co",
  "overall_score": 42,
  "critical_count": 2,
  "executive_summary": "...",
  "top_priority_html": "<strong>...</strong>",
  "generated_at": "2025-01-01T12:00:00Z",
  "risks": [
    {
      "rank": 1,
      "question_id": "q_cash_runway",
      "risk_name": "Cash Runway",
      "probability": 8,
      "impact": 9,
      "score": 72,
      "tier": "watch",
      "hedge": "AI-generated mitigation narrative..."
    }
  ]
}
```

---

## Architecture Notes

### Session auth
There are no user accounts. Each session is identified by a UUID and protected by a 32-byte random `anon_token` stored in the browser's `sessionStorage` and sent on every request as `X-Anon-Token`. The middleware verifies the token matches the session ID in the URL, preventing cross-session access even if tokens leak.

### Payment flow
Checkout uses Stripe's PaymentIntents API with a client-side confirmation model â€” the server creates the intent, returns the `client_secret` to the browser, and Stripe.js handles the card UI and 3DS. The server learns the result via webhook, never via a redirect.

The `store.AttachPaymentIntent` write uses a serializable transaction so concurrent checkout calls for the same session are safe â€” the second caller receives the existing intent's secret rather than creating a duplicate.

### Scoring
The `scoring` package is intentionally dependency-free. `ComputeRisks()` takes `[]AnswerRow` (a plain Go struct) and returns `[]ScoredRisk` without touching the database or any other internal package. This makes it trivially testable and reusable.

Risk tiers follow a 2Ã—2 probability/impact matrix:

| | High Impact (â‰¥7) | Low Impact (<7) |
|---|---|---|
| **High Prob (â‰¥6)** | ðŸ”´ Watch | ðŸŸ¡ Manage |
| **Low Prob (<6)** | ðŸŸ  Red | âšª Ignore |

### Worker
The worker is an in-process polling loop â€” no external queue needed. `runner.go` claims jobs with a `SELECT ... FOR UPDATE SKIP LOCKED` query (via sqlc), runs `job.go`, and updates the report status. The `JobTimeout` context deadline prevents runaway AI calls from blocking a worker slot indefinitely.

### AI fallback
`ai.FallbackHedger` wraps two `Hedger` implementations. On a primary error it logs the failure and transparently retries with the secondary. If the AI call fails entirely, the worker falls back to the static hedge text stored in `question_definitions.hedge`.

---

## Running Tests

```bash
# All tests
go test ./...

# Scoring unit tests only (no DB needed)
go test ./internal/scoring/...

# Store integration tests (requires DATABASE_URL to be set)
go test ./internal/store/...

# With race detector
go test -race ./...

# With coverage
go test -cover ./...
```

Store tests use real transactions that are always rolled back â€” they require a live database but leave it completely clean.

---

## Docker

```bash
# Build the image (~15 MB, scratch-based)
docker build -t asymmetric-risk-mapper:latest .

# Full local stack (Postgres on :5433 to avoid conflicts with a local install)
docker compose up --build

# API only (assumes Postgres is already running)
docker compose up api
```

The Dockerfile uses a two-stage build: `golang:1.23-alpine` compiles a fully static binary, which is copied into a `scratch` image with only the CA bundle and timezone data alongside it.

---

## Deployment

The application is a single stateless binary. Any platform that runs Docker containers works out of the box.

### Railway (recommended for quick deploys)
1. Connect your GitHub repo in the Railway dashboard.
2. Railway detects the `Dockerfile` automatically.
3. Add a Postgres plugin â€” Railway injects `DATABASE_URL` automatically.
4. Set all remaining environment variables in the Railway variables panel.
5. Set `ENV=production`.

### Fly.io
```bash
fly launch          # generates fly.toml from the Dockerfile
fly secrets set STRIPE_SECRET_KEY=sk_live_... ANTHROPIC_API_KEY=...
fly deploy
```

### Stripe webhook in production
After deploying, register the webhook endpoint in the [Stripe Dashboard](https://dashboard.stripe.com/webhooks):

- **Endpoint URL:** `https://your-domain.com/api/webhooks/stripe`
- **Events to listen for:** `payment_intent.succeeded`, `payment_intent.payment_failed`, `charge.refunded`
- Copy the signing secret into `STRIPE_WEBHOOK_SECRET`.

For local webhook testing:
```bash
stripe listen --forward-to localhost:8080/api/webhooks/stripe
```
